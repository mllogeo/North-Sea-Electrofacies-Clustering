{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* System Append to set proper path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import time\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.Utils import welllog\n",
    "from Source.Utils import multi_df\n",
    "from Source.Utils import well_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tqdm Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Miscellaneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../Data/Lithology code data.xlsx'\n",
    "\n",
    "file_path2 = '../Data/NPD stratigraphic picks north sea.xlsx'\n",
    "\n",
    "litho_code = pd.read_excel(file_path)\n",
    "\n",
    "picks = pd.read_excel(file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lithology Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_code.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Fixing Columns IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_code.columns = litho_code.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Droping first row (as it has become the columns ids now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_code.drop(index=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Checking Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_code.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stratigraphic Picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Renaming Unidentified Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks.rename(columns={'Unnamed: 0': 'Unidentified Column'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Checking Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Las files Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../Data/GEOLINK_Lithology and wells NORTH SEA/'\n",
    "\n",
    "npd_wells = welllog.read_las_directory(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las files Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of Las Files read: ' + str(len(npd_wells)))\n",
    "print('##########################')\n",
    "print('Las files ID: ' + str(npd_wells.keys()))\n",
    "print('##########################')\n",
    "print(str(npd_wells['15_9-12'].curves))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd_wells['15_9-12'].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Note: The Mnmonic Table above does not necessarily represent all the available log curves on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Dataframe Building and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking unmatching unit of measurement for each log curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unit_mismatch_list = welllog.unit_check(npd_wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Converting all las files to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "npd_wells_df = {}\n",
    "\n",
    "for id in tqdm_notebook(list(npd_wells.keys()), desc='Converting to dataframe'):\n",
    "\n",
    "    npd_wells_df[id] = npd_wells[id].df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Filling in Log Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logs_dict = welllog.log_frame(npd_wells_df, logs_list, mode='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating Main Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Creating Well ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id in tqdm_notebook(list(npd_wells_df.keys()), desc='Adding Well Name Column'):\n",
    "\n",
    "    npd_wells_df[id]['WELL_NAME'] = id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Converting Depth to a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id in tqdm_notebook(list(npd_wells_df.keys()), desc='Adding Depth Column'):\n",
    "\n",
    "    npd_wells_df[id]['DEPTH'] = npd_wells_df[id].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Selected Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_list = ['DEPTH','LITHOLOGY_GEOLINK', 'CALI', 'NPHI', 'RHOB', 'GR', 'DTC', 'RDEP', 'WELL_NAME']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Creating Empty Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.DataFrame(columns= logs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Filling Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id in tqdm_notebook(list(npd_wells_df.keys()), desc='Adding Depth Column'):\n",
    "\n",
    "    tmp = []\n",
    "\n",
    "    for i in range(len(logs_list)):\n",
    "\n",
    "        if logs_list[i] in npd_wells_df[id].columns:\n",
    "\n",
    "            tmp.append(logs_list[i])\n",
    "\n",
    "    df_main = df_main.append(npd_wells_df[id][tmp], ignore_index=True)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lithology Code Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_code_dict = {}\n",
    "\n",
    "for row_val in litho_code.index:\n",
    "\n",
    "    litho_code_dict[litho_code['Abbreviation'][row_val]] = litho_code['Lithology Attribute'][row_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_code_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat_df = abs(df_main.corr()) # absolute correlation\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.heatmap(corrmat_df, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mixer Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.set()\n",
    "\n",
    "sns.pairplot(df_main.dropna().sample(1000))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distribution Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Lithology_Geoling Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK.values); \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LITHOLOGY_GEOLINK distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * CALI Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.CALI.notnull()].CALI.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.CALI.notnull()].CALI.values); \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('CALI distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * NPHI Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.NPHI.notnull()].NPHI.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.NPHI.notnull()].NPHI.values);\n",
    "#plt.xlim(0,100) \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('NPHI distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.set_start_method('spawn', True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "NUM_CORES = 30\n",
    "\n",
    "df_chunks_out_count = np.array_split(df_main, NUM_CORES)\n",
    "\n",
    "with multiprocessing.Pool(NUM_CORES) as pool:\n",
    "\n",
    "    df_main = pd.concat(pool.map(multi_df.nphi_filtering, df_chunks_out_count), ignore_index=True)\n",
    "\n",
    "print(str(round((time.time() - start_time)/60,1)) + ' minutes taken') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * RHOB Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.RHOB.notnull()].RHOB.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.RHOB.notnull()].RHOB.values); \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('RHOB distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * GR Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.GR.notnull()].GR.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.GR.notnull()].GR.values); \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('GR distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * DTC Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.DTC.notnull()].DTC.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.DTC.notnull()].DTC.values); \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('DTC distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * RDEP Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu, sigma) = stats.norm.fit(df_main[df_main.RDEP.notnull()].RDEP.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.distplot(df_main[df_main.RDEP.notnull()].RDEP.values); \n",
    "\n",
    "plt.legend('Normal distribution')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('RDEP distribution -- Mu:' + ' ' + str(mu) + ' ' + 'Sigma:' + ' ' + str(sigma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Relationship with the categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * CALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data = pd.concat([df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK, df_main[df_main.LITHOLOGY_GEOLINK.notnull()].CALI], axis=1)\n",
    "fig = sns.boxplot(x=\"LITHOLOGY_GEOLINK\", y='CALI', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * NPHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data = pd.concat([df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK, df_main[df_main.LITHOLOGY_GEOLINK.notnull()].NPHI], axis=1)\n",
    "fig = sns.boxplot(x=\"LITHOLOGY_GEOLINK\", y='NPHI', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * RHOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data = pd.concat([df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK, df_main[df_main.LITHOLOGY_GEOLINK.notnull()].RHOB], axis=1)\n",
    "fig = sns.boxplot(x=\"LITHOLOGY_GEOLINK\", y='RHOB', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * GR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data = pd.concat([df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK, df_main[df_main.LITHOLOGY_GEOLINK.notnull()].GR], axis=1)\n",
    "fig = sns.boxplot(x=\"LITHOLOGY_GEOLINK\", y='GR', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data = pd.concat([df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK, df_main[df_main.LITHOLOGY_GEOLINK.notnull()].DTC], axis=1)\n",
    "fig = sns.boxplot(x=\"LITHOLOGY_GEOLINK\", y='DTC', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * RDEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data = pd.concat([df_main[df_main.LITHOLOGY_GEOLINK.notnull()].LITHOLOGY_GEOLINK, df_main[df_main.LITHOLOGY_GEOLINK.notnull()].RDEP], axis=1)\n",
    "fig = sns.boxplot(x=\"LITHOLOGY_GEOLINK\", y='RDEP', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Outliers Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Number of outliers per row column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'Number of Outliers'\n",
    "\n",
    "df_main[val] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Non-Outlier Ranges (Expert Provided) (Used inside classify_outliers function! In here only for display purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {}\n",
    "\n",
    "ranges['CALI'] = [0, 30]\n",
    "\n",
    "ranges['NPHI'] = [0.1, 0.65] \n",
    "\n",
    "ranges['RHOB'] = [1, 4] \n",
    "\n",
    "ranges['GR'] = [0, 200]\n",
    "\n",
    "ranges['DTC'] = [40, 200]\n",
    "\n",
    "ranges['RDEP'] = [0.0001, 6000] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Filling in the Numbers of Outliers Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.set_start_method('spawn', True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "NUM_CORES = 30\n",
    "\n",
    "df_chunks_out_count = np.array_split(df_main, NUM_CORES)\n",
    "\n",
    "with multiprocessing.Pool(NUM_CORES) as pool:\n",
    "\n",
    "    df_main = pd.concat(pool.map(multi_df.classify_outliers, df_chunks_out_count), ignore_index=True)\n",
    "\n",
    "print(str(round((time.time() - start_time)/60,1)) + ' minutes taken') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Dropping Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "NUM_CORES = 30\n",
    "\n",
    "df_chunks_out_count = np.array_split(df_main, NUM_CORES)\n",
    "\n",
    "with multiprocessing.Pool(NUM_CORES) as pool:\n",
    "\n",
    "    df_main = pd.concat(pool.map(multi_df.remove_outliers_class, df_chunks_out_count), ignore_index=True)\n",
    "\n",
    "print(str(round((time.time() - start_time)/60,1)) + ' minutes taken') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null Values Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Raw Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = df_main.columns.to_list()\n",
    "\n",
    "columns.remove('LITHOLOGY_GEOLINK')\n",
    "\n",
    "columns.remove('DEPTH')\n",
    "\n",
    "columns.remove('WELL_NAME')\n",
    "\n",
    "columns.remove('Number of Outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.barplot(x=df_main.isnull().sum().index, y=df_main.isnull().sum()) # only considering variables of interest\n",
    "plt.xticks(rotation='90')\n",
    "plt.xlabel('Variables', fontsize=10)\n",
    "plt.ylabel('Total missing values (Not a Number)', fontsize=10) # Not counting -999,25\n",
    "plt.title('Total missing values (Not a Number)', fontsize=15) # Not counting -999,25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Closer Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.barplot(x=df_main[columns].isnull().sum().index, y=df_main[columns].isnull().sum()) # only considering variables of interest\n",
    "plt.xticks(rotation='90')\n",
    "plt.xlabel('Variables', fontsize=10)\n",
    "plt.ylabel('Total missing values (Not a Number)', fontsize=10) # Not counting -999,25\n",
    "plt.title('Total missing values (Not a Number)', fontsize=15) # Not counting -999,25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Dropping Rows for Null values in Pivot Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.dropna(subset=['CALI', 'RHOB', 'GR', 'DTC', 'RDEP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.barplot(x=df_main.isnull().sum().index, y=df_main.isnull().sum()) # only considering variables of interest\n",
    "plt.xticks(rotation='90')\n",
    "plt.xlabel('Variables', fontsize=10)\n",
    "plt.ylabel('Total missing values (Not a Number)', fontsize=10) \n",
    "plt.title('Total missing values (Not a Number)', fontsize=15) "
   ]
  },
  {
   "source": [
    "# Checkpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_lito_code = '../checkpoints/litho_code.csv.gz'\n",
    "\n",
    "path_file_picks = '../checkpoints/picks.csv.gz'\n",
    "\n",
    "path_file_df_main = '../checkpoints/df_main.csv.gz'\n",
    "\n",
    "litho_code.to_csv(path_file_lito_code,index=False, compression='gzip')\n",
    "\n",
    "picks.to_csv(path_file_picks,index=False, compression='gzip')\n",
    "\n",
    "df_main.to_csv(path_file_df_main,index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('phase1': conda)",
   "display_name": "Python 3.7.6 64-bit ('phase1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "43575a95c5fa30f9c9f84c3d0129ba3f77c9622d889edcecf3dad2a10ecf7387"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}